{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio, display\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport itertools\n\nimport librosa\nimport librosa.display\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn import preprocessing\nfrom keras.layers import Dense, BatchNormalization, Dropout, LSTM\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom keras import callbacks\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n\nfrom tqdm import tqdm\nfrom IPython.display import Audio, display\n\nfrom keras.utils import np_utils\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-05-23T14:06:12.098239Z","iopub.execute_input":"2023-05-23T14:06:12.098637Z","iopub.status.idle":"2023-05-23T14:06:12.111034Z","shell.execute_reply.started":"2023-05-23T14:06:12.098606Z","shell.execute_reply":"2023-05-23T14:06:12.109541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loding The Data","metadata":{}},{"cell_type":"code","source":"files_Path='../input/speech-emotion-recognition-en/Crema/'\n\nc_emotions = {\n    'NEU':'neutral',\n    'HAP':'happy',\n    'SAD':'sad',\n    'ANG':'angry',\n    'FEA':'fear',\n    'DIS':'disgust'}\n\nc_file = []\nfor wav in os.listdir(files_Path):\n    emo = wav.partition(\".wav\")[0].split('_')\n    emotion = c_emotions[emo[2]]\n    c_file.append((files_Path+'/'+wav,emotion))\n    \ndata_df = pd.DataFrame(c_file, columns = ['File_path', 'Emotion'])\ndata_df.to_csv('data_df.csv')\ndata_df.shape\ndata_df.head(10)    ","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:06:12.113776Z","iopub.execute_input":"2023-05-23T14:06:12.115714Z","iopub.status.idle":"2023-05-23T14:06:12.228125Z","shell.execute_reply.started":"2023-05-23T14:06:12.115671Z","shell.execute_reply":"2023-05-23T14:06:12.226606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Analysis","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport librosa\n\ndef create_waveplot(data, sampling_rate, emotion):\n    plt.figure(figsize=(10, 3))\n    plt.title(f'Waveplot for audio with {emotion} emotion', size=15)\n    plt.plot(data)\n    plt.xlabel('Time')\n    plt.ylabel('Amplitude')\n    plt.show()\n\nfor emotion in c_emotions.values():\n    # get the path of the first happy record\n    path = (data_df[data_df.Emotion == emotion].iloc[0])[0]\n    data, sampling_rate = librosa.load(path)\n    create_waveplot(data,sampling_rate,emotion)\n    # create_spectrogram(data, sampling_rate, emotion)\n    display(Audio(path))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:06:12.229532Z","iopub.execute_input":"2023-05-23T14:06:12.229880Z","iopub.status.idle":"2023-05-23T14:06:13.859641Z","shell.execute_reply.started":"2023-05-23T14:06:12.229842Z","shell.execute_reply":"2023-05-23T14:06:13.858078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use(\"ggplot\")\ncols= [\"#6dbf9f\",\"#774571\",\"#234554\",\"#45d874\",\"#864525\",\"#691285\"]\nplt.title(\"Count of emotions\")\nsns.countplot(x = data_df[\"Emotion\"], palette= cols)\nsns.despine(top = True, right = True, left = False, bottom = False)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:06:13.863291Z","iopub.execute_input":"2023-05-23T14:06:13.863782Z","iopub.status.idle":"2023-05-23T14:06:14.133903Z","shell.execute_reply.started":"2023-05-23T14:06:13.863736Z","shell.execute_reply":"2023-05-23T14:06:14.132491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"note: the data seems to be somewhat balanced.\n","metadata":{}},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"code","source":"def add_noise(data,random=False,rate=0.035,threshold=0.075):\n    if random:\n        rate=np.random.random()*threshold\n    noise=rate*np.random.uniform()*np.amax(data)\n    augmented_data=data+noise*np.random.normal(size=data.shape[0])\n    return augmented_data\n\ndef pitching(data,sr,pitch_factor=0.7,random=False):\n    if random:\n        pitch_factor=np.random.random() * pitch_factor\n    return librosa.effects.pitch_shift(y=data,sr=sr,n_steps=pitch_factor)\n#-------------------------------------------------------------------------------------------\ndef zcr(data,frame_length,hop_length):\n    zcr=librosa.feature.zero_crossing_rate(y=data,frame_length=frame_length,hop_length=hop_length)\n    return np.squeeze(zcr)\ndef rmse(data,frame_length=2048,hop_length=512):\n    rmse=librosa.feature.rms(y=data,frame_length=frame_length,hop_length=hop_length)\n    return np.squeeze(rmse)\ndef mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n    mfcc=librosa.feature.mfcc(y=data,sr=sr)\n    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n#-------------------------------------------------------------------------------------------\ndef extract_features(data,sr,frame_length=2048,hop_length=512):\n    result=np.array([])\n    \n    result=np.hstack((result,\n                      zcr(data,frame_length,hop_length),\n                      rmse(data,frame_length,hop_length),\n                      mfcc(data,sr,frame_length,hop_length)\n                     ))\n    return result\n\ndef get_features(path,duration=2.5, offset=0.6):\n    data,sr=librosa.load(path,duration=duration,offset=offset)\n    aud=extract_features(data,sr)\n    audio=np.array(aud)\n    \n    noised_audio=add_noise(data,random=True)\n    aud2=extract_features(noised_audio,sr)\n    audio=np.vstack((audio,aud2))\n    \n    pitched_audio=pitching(data,sr,random=True)\n    aud3=extract_features(pitched_audio,sr)\n    audio=np.vstack((audio,aud3))\n    \n    return audio\n#-------------------------------------------------------------------------------------------\nX, Y = [], []\n\nfor path, emotion, index in zip(data_df.File_path, data_df.Emotion, range(data_df.File_path.shape[0])):\n    features = get_features(path)\n    if index % 500 == 0:\n        print(f'{index} audio has been processed')\n    for i in features:\n        X.append(i)\n        Y.append(emotion)\n\nprint('Done')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:06:14.135785Z","iopub.execute_input":"2023-05-23T14:06:14.136148Z","iopub.status.idle":"2023-05-23T14:28:05.619168Z","shell.execute_reply.started":"2023-05-23T14:06:14.136117Z","shell.execute_reply":"2023-05-23T14:28:05.617475Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_data_path='./processed_data.csv'","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:28:05.622424Z","iopub.execute_input":"2023-05-23T14:28:05.623403Z","iopub.status.idle":"2023-05-23T14:28:05.630776Z","shell.execute_reply.started":"2023-05-23T14:28:05.623356Z","shell.execute_reply":"2023-05-23T14:28:05.629142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract=pd.DataFrame(X)\nextract['Emotion']=Y\nextract.to_csv(processed_data_path,index=False)\nextract.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:28:05.633778Z","iopub.execute_input":"2023-05-23T14:28:05.634736Z","iopub.status.idle":"2023-05-23T14:30:29.624370Z","shell.execute_reply.started":"2023-05-23T14:28:05.634688Z","shell.execute_reply":"2023-05-23T14:30:29.623063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(processed_data_path)\ndf.shape\n\ndf=df.fillna(0)\nprint(df.isna().any())\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:30:29.626382Z","iopub.execute_input":"2023-05-23T14:30:29.627259Z","iopub.status.idle":"2023-05-23T14:30:46.195181Z","shell.execute_reply.started":"2023-05-23T14:30:29.627219Z","shell.execute_reply":"2023-05-23T14:30:46.193700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail(10)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:30:46.196906Z","iopub.execute_input":"2023-05-23T14:30:46.197573Z","iopub.status.idle":"2023-05-23T14:30:46.234506Z","shell.execute_reply.started":"2023-05-23T14:30:46.197527Z","shell.execute_reply":"2023-05-23T14:30:46.233128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df.drop(labels='Emotion',axis=1)\nY=df['Emotion']\nlb=LabelEncoder()\nY=np_utils.to_categorical(lb.fit_transform(Y))\nprint(lb.classes_)\nY","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:30:46.239611Z","iopub.execute_input":"2023-05-23T14:30:46.240042Z","iopub.status.idle":"2023-05-23T14:30:46.412277Z","shell.execute_reply.started":"2023-05-23T14:30:46.239997Z","shell.execute_reply":"2023-05-23T14:30:46.411032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,Y,random_state=32,test_size=0.2,shuffle=True)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape\n\nX_train,X_val,y_train,y_val = train_test_split(X_train,y_train,random_state=32,test_size=0.1,shuffle=True)\nX_train.shape, X_test.shape, X_val.shape, y_train.shape,y_test.shape,y_val.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:30:46.413785Z","iopub.execute_input":"2023-05-23T14:30:46.414192Z","iopub.status.idle":"2023-05-23T14:30:46.994829Z","shell.execute_reply.started":"2023-05-23T14:30:46.414160Z","shell.execute_reply":"2023-05-23T14:30:46.992990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler=StandardScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\nX_val=scaler.transform(X_val)\nX_train.shape,X_test.shape,X_val.shape,y_train.shape,y_test.shape,y_val.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:30:46.996339Z","iopub.execute_input":"2023-05-23T14:30:46.996704Z","iopub.status.idle":"2023-05-23T14:30:47.732731Z","shell.execute_reply.started":"2023-05-23T14:30:46.996672Z","shell.execute_reply":"2023-05-23T14:30:47.731071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=np.expand_dims(X_train,axis=2)\nX_val=np.expand_dims(X_val,axis=2)\nX_test=np.expand_dims(X_test,axis=2)\nX_train.shape, X_test.shape, X_val.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-23T14:34:46.680259Z","iopub.execute_input":"2023-05-23T14:34:46.680752Z","iopub.status.idle":"2023-05-23T14:34:46.692002Z","shell.execute_reply.started":"2023-05-23T14:34:46.680717Z","shell.execute_reply":"2023-05-23T14:34:46.690507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.layers as L\nimport tensorflow as tf\nfrom keras.callbacks import ReduceLROnPlateau\nearly_stop = callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=5, restore_best_weights=True)\nlr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.1, min_lr=0.00001)\nEPOCH=50\nBATCH_SIZE=30\n\nmodel=tf.keras.Sequential([\n    L.Conv1D(32,kernel_size=6, strides=1,padding='same', activation='relu',input_shape=(X_train.shape[1],1)),\n    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n    L.Conv1D(64,kernel_size=6,strides=1,padding='same',activation='relu'),\n    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n    L.Conv1D(128,kernel_size=6,strides=1,padding='same',activation='relu'),\n    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n    L.Flatten(),\n    L.Dense(256,activation='relu'),\n    L.Dropout(0.5),\n    L.Dense(6,activation='softmax')\n])\nmodel.compile(optimizer='nadam',loss='categorical_crossentropy',metrics='accuracy')\nhistory=model.fit(X_train, y_train, epochs=EPOCH, validation_data=(X_val,y_val), batch_size=BATCH_SIZE,callbacks=[early_stop,lr_reduction])","metadata":{"execution":{"iopub.status.busy":"2023-05-23T15:15:23.799687Z","iopub.execute_input":"2023-05-23T15:15:23.800302Z","iopub.status.idle":"2023-05-23T16:14:50.471659Z","shell.execute_reply.started":"2023-05-23T15:15:23.800257Z","shell.execute_reply":"2023-05-23T16:14:50.470364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_accuracy = np.mean(history.history['val_accuracy'])\nprint(\"\\n%s: %.2f%%\" % ('val_accuracy', val_accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2023-05-23T16:14:56.803882Z","iopub.execute_input":"2023-05-23T16:14:56.804333Z","iopub.status.idle":"2023-05-23T16:14:56.812017Z","shell.execute_reply.started":"2023-05-23T16:14:56.804299Z","shell.execute_reply":"2023-05-23T16:14:56.810625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\n\nplt.plot(history_df.loc[:, ['loss']], \"#6daa9f\", label='Training loss')\nplt.plot(history_df.loc[:, ['val_loss']],\"#774571\", label='Validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(loc=\"best\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-23T16:14:59.165531Z","iopub.execute_input":"2023-05-23T16:14:59.165949Z","iopub.status.idle":"2023-05-23T16:14:59.524911Z","shell.execute_reply.started":"2023-05-23T16:14:59.165918Z","shell.execute_reply":"2023-05-23T16:14:59.523752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\n\nplt.plot(history_df.loc[:, ['accuracy']], \"#6daa9f\", label='Training accuracy')\nplt.plot(history_df.loc[:, ['val_accuracy']], \"#774571\", label='Validation accuracy')\n\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-23T16:15:03.228786Z","iopub.execute_input":"2023-05-23T16:15:03.229617Z","iopub.status.idle":"2023-05-23T16:15:03.549790Z","shell.execute_reply.started":"2023-05-23T16:15:03.229580Z","shell.execute_reply":"2023-05-23T16:15:03.548475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting the test set results\ny_pred = model.predict(X_test)\ny_pred = (y_pred > 0.5)\nnp.set_printoptions()","metadata":{"execution":{"iopub.status.busy":"2023-05-23T16:15:06.634790Z","iopub.execute_input":"2023-05-23T16:15:06.636071Z","iopub.status.idle":"2023-05-23T16:15:17.128018Z","shell.execute_reply.started":"2023-05-23T16:15:06.636012Z","shell.execute_reply":"2023-05-23T16:15:17.126566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n# confusion matrix\ny_test_labels = np.argmax(y_test, axis=1)\ny_pred_labels = np.argmax(y_pred, axis=1)\nconf=confusion_matrix(y_test_labels,y_pred_labels)\ncmap1 = sns.diverging_palette(275,100,  s=40, l=65, n=6)\ncm=pd.DataFrame(\n    conf,index=[i for i in c_emotions.values()],\n    columns=[i for i in c_emotions.values()]\n)\nplt.figure(figsize=(12,7))\nax=sns.heatmap(cm,annot=True,fmt='d')\nax.set_title(f'confusion matrix for model ')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-23T16:15:19.646535Z","iopub.execute_input":"2023-05-23T16:15:19.647209Z","iopub.status.idle":"2023-05-23T16:15:20.162740Z","shell.execute_reply.started":"2023-05-23T16:15:19.647166Z","shell.execute_reply":"2023-05-23T16:15:20.160807Z"},"trusted":true},"execution_count":null,"outputs":[]}]}